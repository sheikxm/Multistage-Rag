# -*- coding: utf-8 -*-
"""multistagerag.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yN13UNhs1GS-b7pq4VHROgJeiUlqnqKG
"""

!pip install datasets sentence-transformers faiss-cpu transformers

from datasets import load_dataset
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from transformers import AutoModelForSequenceClassification, AutoTokenizer
import torch

dataset = load_dataset("hotpotqa/hotpot_qa", "distractor") # or "fullwiki"

print("Sample data: ", dataset['train'][0])

def chunk_text(text, chunk_size=150):
    words = text.split()
    return [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]

dataset['train'] = dataset['train'].map(lambda x: {'chunks': chunk_text(x.get('text', ''))},
                                      num_proc=4)



print("Chunked passages: ", dataset['train'][10]['chunks'])

embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

def embed_passages(passages):
    return embedding_model.encode(passages, convert_to_tensor=True)

dataset['train'] = dataset['train'].map(lambda x: {'embeddings': embed_passages(x['chunks'])})

# Instead of replacing the entire dataset entry, add the 'embeddings' field:
dataset['train'] = dataset['train'].map(lambda x: x.update({'embeddings': embed_passages(x['chunks'])}) or x)
# 'or x' ensures the original data is returned if update fails

# Check if 'embeddings' is populated and is a list before accessing its elements:
if 'embeddings' in dataset['train'][0] and len(dataset['train'][0]['embeddings']) > 0:
    print("Embeddings: ", dataset['train'][0]['embeddings'][0].shape)
else:
    print("Embeddings not found or empty for the first dataset entry.")